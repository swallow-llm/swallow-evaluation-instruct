{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e614d75",
   "metadata": {},
   "source": [
    "A notebook to test a pair of a provider and a model: \\\n",
    "This implementation is based on \"3.4 特定のproviderでエラーが出る場合の対応\" in `README_t4.md`.\n",
    "\n",
    "Setup: \\\n",
    "To use this notebook, you need to use `python>=3.10.0` and install as follows\n",
    "```\n",
    "pip install \"../../lighteval[math,extended_tasks,litellm,vllm]\" \"transformers>=4.51.0,<4.53.0\" \"openai>=1.40.0\" \"datasets<4.0.0\" \"ipywidgets\"\n",
    "```\n",
    "This lineup can be changed due to an update or your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61836f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "assert load_dotenv('../../.env'), \"Failed to load .env file\"\n",
    "\n",
    "import litellm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_base_url(provider):\n",
    "    base_url_dict = {\n",
    "        \"openai\": \"https://api.openai.com/v1\",\n",
    "        \"deepinfra\": \"https://api.deepinfra.com/v1/openai\",\n",
    "        \"vllm\": \"http://localhost:8000/v1\",\n",
    "    }\n",
    "    return base_url_dict[provider]\n",
    "\n",
    "def get_api_key(provider):\n",
    "    api_name_dict = {\n",
    "        \"openai\": \"OPENAI_API_KEY\",\n",
    "        \"deepinfra\": \"DEEPINFRA_API_KEY\",\n",
    "        \"vllm\": None,\n",
    "    }\n",
    "    return os.getenv(api_name_dict[provider]) if api_name_dict[provider] else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03544e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "provider = \"vllm\"\n",
    "base_url = get_base_url(provider)\n",
    "\n",
    "model = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5\"\n",
    "\n",
    "optional_params = {\n",
    "    # You should refer to the official documentation for the parameters: https://docs.litellm.ai/docs/api-reference/litellm.completion.\n",
    "    \"n\": 2,\n",
    "    \"temperature\": 0.6,\n",
    "    \"max_tokens\": 128,\n",
    "}\n",
    "\n",
    "api_key = get_api_key(provider)\n",
    "if api_key != \"\": optional_params[\"api_key\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b14423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a test prompt\n",
    "test_prompt = \"こんにちは。なにかしゃべって\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f566dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request payload\n",
    "request_payload = {\n",
    "    \"model\": f\"{provider}/{model}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": test_prompt,\n",
    "        }\n",
    "    ],\n",
    "    \"logprobs\": None,\n",
    "    \"caching\": False,\n",
    "    \"base_url\": base_url,\n",
    "    **optional_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12545bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'vllm/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5',\n",
       " 'messages': [{'role': 'user', 'content': 'こんにちは。なにかしゃべって'}],\n",
       " 'logprobs': None,\n",
       " 'caching': False,\n",
       " 'base_url': 'http://localhost:8000/v1',\n",
       " 'n': 2,\n",
       " 'temperature': 0.6,\n",
       " 'max_tokens': 128}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the payload\n",
    "request_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02b659e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it, est. speed input: 21.92 toks/s, output: 101.59 toks/s]\n"
     ]
    }
   ],
   "source": [
    "# Get responses (this takes a while)\n",
    "responses = litellm.completion(**request_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "943dd53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-50b6f2a1-0f24-4c2c-b715-7c1b44efa2e1', created=1752474184, model='tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='こんにちは！何かお話したいことはありますか？😊\\n\\n例えば、\\n\\n*   **雑談**：最近あった面白いこと、好きなこと、興味のあることなど\\n*   **質問**：何か知りたいこと、困っていること\\n*   **お願い**：何か手伝ってほしいこと、相談したいこと\\n*   **ゲーム**：簡単なクイズやなぞなぞ\\n\\nどんなことでも構いませんので、お気軽にお話くださいね。', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=115, prompt_tokens=41, total_tokens=156, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b10d67f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！何かお話したいことはありますか？😊\n",
      "\n",
      "例えば、\n",
      "\n",
      "*   **雑談**：最近あった面白いこと、好きなこと、興味のあることなど\n",
      "*   **質問**：何か知りたいこと、困っていること\n",
      "*   **お願い**：何か手伝ってほしいこと、相談したいこと\n",
      "*   **ゲーム**：簡単なクイズやなぞなぞ\n",
      "\n",
      "どんなことでも構いませんので、お気軽にお話くださいね。\n"
     ]
    }
   ],
   "source": [
    "print(responses.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_debug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
