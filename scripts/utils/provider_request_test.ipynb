{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e614d75",
   "metadata": {},
   "source": [
    "A notebook to test a pair of a provider and a model: \\\n",
    "This implementation is based on \"3.4 ç‰¹å®šã®providerã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã®å¯¾å¿œ\" in `README_t4.md`.\n",
    "\n",
    "Setup: \\\n",
    "To use this notebook, you need to use `python>=3.10.0` and install as follows\n",
    "```\n",
    "pip install \"../../lighteval[math,extended_tasks,litellm,vllm]\" \"transformers>=4.51.0,<4.53.0\" \"openai>=1.40.0\" \"datasets<4.0.0\" \"ipywidgets\"\n",
    "```\n",
    "This lineup can be changed due to an update or your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61836f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "assert load_dotenv('../../.env'), \"Failed to load .env file\"\n",
    "\n",
    "import litellm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_base_url(provider):\n",
    "    base_url_dict = {\n",
    "        \"openai\": \"https://api.openai.com/v1\",\n",
    "        \"deepinfra\": \"https://api.deepinfra.com/v1/openai\",\n",
    "        \"vllm\": \"http://localhost:8000/v1\",\n",
    "    }\n",
    "    return base_url_dict[provider]\n",
    "\n",
    "def get_api_key(provider):\n",
    "    api_name_dict = {\n",
    "        \"openai\": \"OPENAI_API_KEY\",\n",
    "        \"deepinfra\": \"DEEPINFRA_API_KEY\",\n",
    "        \"vllm\": None,\n",
    "    }\n",
    "    return os.getenv(api_name_dict[provider]) if api_name_dict[provider] else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03544e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "provider = \"vllm\"\n",
    "base_url = get_base_url(provider)\n",
    "\n",
    "model = \"tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5\"\n",
    "\n",
    "optional_params = {\n",
    "    # You should refer to the official documentation for the parameters: https://docs.litellm.ai/docs/api-reference/litellm.completion.\n",
    "    \"n\": 2,\n",
    "    \"temperature\": 0.6,\n",
    "    \"max_tokens\": 128,\n",
    "}\n",
    "\n",
    "api_key = get_api_key(provider)\n",
    "if api_key != \"\": optional_params[\"api_key\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b14423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a test prompt\n",
    "test_prompt = \"ã“ã‚“ã«ã¡ã¯ã€‚ãªã«ã‹ã—ã‚ƒã¹ã£ã¦\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f566dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request payload\n",
    "request_payload = {\n",
    "    \"model\": f\"{provider}/{model}\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": test_prompt,\n",
    "        }\n",
    "    ],\n",
    "    \"logprobs\": None,\n",
    "    \"caching\": False,\n",
    "    \"base_url\": base_url,\n",
    "    **optional_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12545bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'vllm/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5',\n",
       " 'messages': [{'role': 'user', 'content': 'ã“ã‚“ã«ã¡ã¯ã€‚ãªã«ã‹ã—ã‚ƒã¹ã£ã¦'}],\n",
       " 'logprobs': None,\n",
       " 'caching': False,\n",
       " 'base_url': 'http://localhost:8000/v1',\n",
       " 'n': 2,\n",
       " 'temperature': 0.6,\n",
       " 'max_tokens': 128}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the payload\n",
    "request_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02b659e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.87s/it, est. speed input: 21.92 toks/s, output: 101.59 toks/s]\n"
     ]
    }
   ],
   "source": [
    "# Get responses (this takes a while)\n",
    "responses = litellm.completion(**request_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "943dd53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-50b6f2a1-0f24-4c2c-b715-7c1b44efa2e1', created=1752474184, model='tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠè©±ã—ãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼ŸğŸ˜Š\\n\\nä¾‹ãˆã°ã€\\n\\n*   **é›‘è«‡**ï¼šæœ€è¿‘ã‚ã£ãŸé¢ç™½ã„ã“ã¨ã€å¥½ããªã“ã¨ã€èˆˆå‘³ã®ã‚ã‚‹ã“ã¨ãªã©\\n*   **è³ªå•**ï¼šä½•ã‹çŸ¥ã‚ŠãŸã„ã“ã¨ã€å›°ã£ã¦ã„ã‚‹ã“ã¨\\n*   **ãŠé¡˜ã„**ï¼šä½•ã‹æ‰‹ä¼ã£ã¦ã»ã—ã„ã“ã¨ã€ç›¸è«‡ã—ãŸã„ã“ã¨\\n*   **ã‚²ãƒ¼ãƒ **ï¼šç°¡å˜ãªã‚¯ã‚¤ã‚ºã‚„ãªããªã\\n\\nã©ã‚“ãªã“ã¨ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã®ã§ã€ãŠæ°—è»½ã«ãŠè©±ãã ã•ã„ã­ã€‚', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=115, prompt_tokens=41, total_tokens=156, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b10d67f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠè©±ã—ãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼ŸğŸ˜Š\n",
      "\n",
      "ä¾‹ãˆã°ã€\n",
      "\n",
      "*   **é›‘è«‡**ï¼šæœ€è¿‘ã‚ã£ãŸé¢ç™½ã„ã“ã¨ã€å¥½ããªã“ã¨ã€èˆˆå‘³ã®ã‚ã‚‹ã“ã¨ãªã©\n",
      "*   **è³ªå•**ï¼šä½•ã‹çŸ¥ã‚ŠãŸã„ã“ã¨ã€å›°ã£ã¦ã„ã‚‹ã“ã¨\n",
      "*   **ãŠé¡˜ã„**ï¼šä½•ã‹æ‰‹ä¼ã£ã¦ã»ã—ã„ã“ã¨ã€ç›¸è«‡ã—ãŸã„ã“ã¨\n",
      "*   **ã‚²ãƒ¼ãƒ **ï¼šç°¡å˜ãªã‚¯ã‚¤ã‚ºã‚„ãªããªã\n",
      "\n",
      "ã©ã‚“ãªã“ã¨ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã®ã§ã€ãŠæ°—è»½ã«ãŠè©±ãã ã•ã„ã­ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(responses.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_debug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
