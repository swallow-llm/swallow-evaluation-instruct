# You can add custom settings and name them as you like.
# Following are the available settings:
# - system_message
# - max_model_length
# - max_new_tokens
# - temperature
# - top_p
# - max_n
# - reasoning_parser (Available parsers: https://docs.vllm.ai/en/stable/features/reasoning_outputs.html)

# 'version' is the version of the custom settings.
# You should update this value if you make any changes to the settings.

reasoning:
  temperature: 0.6
  top_p: 0.95
  reasoning_parser: "deepseek_r1"
  version: "1"


reasoning_no_temp:
  top_p: 0.95
  reasoning_parser: "deepseek_r1"
  version: "1"